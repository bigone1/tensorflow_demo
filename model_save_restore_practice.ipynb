{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 总结：\n",
    "\n",
    "## RESTORE本质和initializer()一样，两者可以无限执行和互相覆盖赋值结果。\n",
    "## SAVE/RESTORE有严格的名字匹配机制，自动映射。\n",
    "## 读取的时候，model中必须不少于当前定义的命名空间变量。\n",
    "## 如果实在定义的变量多，tf.train.Saver()指定变量列表（实际情况：不可能不定义其他变量）\n",
    "\n",
    "## placeholder不是variable，自然也不会被存,所以至少不会因为名字等原因干扰模型的读取。\n",
    "\n",
    "## ema_restore = ema.variables_to_restore()，只能算指定了ema和普通变量的绑定关系，不是只有ema，其实包含了变量，并且不影响变量自身的读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简单例子，不过需要重启内核分别执行，因为scope会自动重命名，重命名以后就找不到参数了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save to path: my_net/save_net_1.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"variables_1\"): \n",
    "\tW = tf.Variable([[1,2,3],[3,4,5]], dtype = tf.float32, name='weights')\n",
    "\tb = tf.Variable([[1,2,3]],dtype = tf.float32,name='biases')\n",
    "init = tf.global_variables_initializer()    \n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "\tsess.run(init)\n",
    "\tsave_path = saver.save(sess, \"my_net/save_net_1.ckpt\")\n",
    "\tprint('Save to path:',save_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from my_net/save_net_1.ckpt\n",
      "W2: [[ 1.  2.  3.]\n",
      " [ 3.  4.  5.]]\n",
      "b2: [[ 1.  2.  3.]]\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"variables_1\"):\n",
    "\tW2 = tf.Variable(np.arange(6).reshape((2,3)), dtype=tf.float32,name='weights')\n",
    "\tb2 = tf.Variable(np.arange(3).reshape((1,3)), dtype=tf.float32,name='biases')\n",
    "    \n",
    "init2 = tf.global_variables_initializer()\n",
    "\n",
    "#no need init\n",
    "loader = tf.train.Saver()\n",
    "load_path = \"my_net/save_net_1.ckpt\"\n",
    "with tf.Session() as sess:\n",
    "\tloader.restore(sess, load_path)\n",
    "\tprint(\"W2:\",sess.run(W2))\n",
    "\tprint(\"b2:\",sess.run(b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 因为命名空间冲突问题，需要重启内核\n",
    "每一次都重启内核，重启内核，重启内核！！！！\n",
    "因为此处没变量名，a会自动声明成Variable_1 Variable_2，save到的变量会悦来愈多，所以会产生很多误解。\n",
    "有变量名，同样的名字还是如此，但是读取的时候那个没名字的变量也按Variable_1去找Variable_b，是找不到的。\n",
    "save和restore是严格按变量名的，没有多余的适应功能，比如存一个，两个都用他来恢复，不存在的！！！！\n",
    "Key Variable_1 not found in checkpoint！！！！！！！！！！！！！！！\n",
    "\n",
    "总之，带名字，每次重启内核！！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3,) dtype=int64_ref>\n",
      "<tf.Variable 'Variable_1:0' shape=(2,) dtype=int64_ref>\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "#存\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "SAVE_PATH = './saver_test'#要用相对路径：Parent directory of saver_test doesn't exist, can't save.\n",
    "a = tf.Variable(np.array([1,2,3]))\n",
    "b = tf.Variable(np.array([3,1]))\n",
    "saver = tf.train.Saver()\n",
    "print(a)\n",
    "print(b)\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    if not os.path.exists(SAVE_PATH):\n",
    "        os.mkdir(SAVE_PATH)\n",
    "    saver.save(sess = sess, save_path = SAVE_PATH)\n",
    "    print(sess.run(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saver_test\n",
      "[1 2 3]\n",
      "[2 3 4]\n",
      "INFO:tensorflow:Restoring parameters from ./saver_test\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "#读取：初始化和恢复操作可以互相覆盖赋值操作\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "SAVE_PATH = './saver_test'\n",
    "a = tf.Variable(np.array([2,3,4]))\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess = sess, save_path = SAVE_PATH)\n",
    "    print(sess.run(a))\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(a))\n",
    "    saver.restore(sess = sess, save_path = SAVE_PATH)\n",
    "    print(sess.run(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_1:0' shape=(2,) dtype=int64_ref>\n",
      "INFO:tensorflow:Restoring parameters from ./saver_test\n",
      "[1 2 3]\n",
      "INFO:tensorflow:Restoring parameters from ./saver_test\n",
      "[1 2 3]\n",
      "[3 1]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-01d13c48d13c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#     print(sess.run(b))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'd:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "SAVE_PATH = './saver_test'\n",
    "#读取：对应原来的数据\n",
    "#不指定名字很难对齐，python中的b可不是python中的那个b，现在无论a、b、c，都只找a。\n",
    "#Variable_1和Variable_2吧\n",
    "a = tf.Variable(np.array([2,3,4]))\n",
    "# b = tf.Variable(np.array([1,1,1,1,1,1]))#形状不匹配 lhs shape= [6] rhs shape= [3]\n",
    "c = tf.Variable(np.array([2,1]),name = 'Variable_1')#只存一个a，却能把a赋值给a和c？如果c形状不和a匹配会报错，但是ab都存了，这块会给c按b算，\n",
    "# b = tf.Variable(np.array([2,1]))#\n",
    "\n",
    "#这种默认名字，被前边b和c占了，最好单独起名，Key Variable_2_1 not found in checkpoint\n",
    "#一旦给variable_b命名了，好像其他的也不能去读variable_1了，连锁反应\n",
    "#可以看到，普通方法是无法用一个变量恢复到两个的，总之都有重名和重命名。\n",
    "# d = tf.Variable(np.array([2]),name = 'Variable_1')\n",
    "# print(b)\n",
    "print(c)\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess = sess, save_path = SAVE_PATH)\n",
    "    print(sess.run(a))\n",
    "\n",
    "    saver.restore(sess = sess, save_path = SAVE_PATH)\n",
    "    print(sess.run(a))\n",
    "    print(sess.run(c))\n",
    "#     print(sess.run(b))\n",
    "#     print('d:',sess.run(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 带两个scope的例子：基本和前边相同，除了名字多个斜杠\n",
    "(分别启动内核)\n",
    "当然，你也可以自己加斜杠,仍然是被自动重命名\n",
    "<tf.Variable 'variables_100/biases:0' shape=(1, 3) dtype=float32_ref>\n",
    "<tf.Variable 'variables_101/biases:0' shape=(1, 3) dtype=float32_ref>\n",
    "<tf.Variable 'variables_101/biases_1:0' shape=(1, 3) dtype=float32_ref>\n",
    "\n",
    "#然后就是EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-35223d00ecae>:17: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "variables_100/weights:0\n",
      "variables_100/biases:0\n",
      "variables_101/weights:0\n",
      "variables_101/biases:0\n",
      "variables_102/weights:0\n",
      "variables_102/biases:0\n",
      "global_step:0\n",
      "variables_100_1/weights:0\n",
      "variables_100_1/biases:0\n",
      "variables_101_1/weights:0\n",
      "variables_101_1/biases:0\n",
      "variables_101/biases_1:0\n",
      "variables_100/weights/ExponentialMovingAverage:0\n",
      "variables_100/biases/ExponentialMovingAverage:0\n",
      "variables_101/weights/ExponentialMovingAverage:0\n",
      "variables_101/biases/ExponentialMovingAverage:0\n",
      "variables_102/weights/ExponentialMovingAverage:0\n",
      "variables_102/biases/ExponentialMovingAverage:0\n",
      "variables_100_1/weights/ExponentialMovingAverage:0\n",
      "variables_100_1/biases/ExponentialMovingAverage:0\n",
      "variables_101_1/weights/ExponentialMovingAverage:0\n",
      "variables_101_1/biases/ExponentialMovingAverage:0\n",
      "variables_101/biases_1/ExponentialMovingAverage:0\n",
      "Save to path: my_net/save_net_2.ckpt\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "MOVING_AVERAGE_DECAY = 0.99\n",
    "global_step = tf.Variable(0, trainable=False,name='global_step')\n",
    "x = tf.placeholder(tf.float32, [1,2])#placeholder不是variable，自然也不会被存\n",
    "with tf.variable_scope(\"variables_100\"): \n",
    "\tW = tf.Variable([[1,2,3],[3,4,5]], dtype = tf.float32, name='weights')\n",
    "\tb = tf.Variable([[1,2,3]],dtype = tf.float32,name='biases')\n",
    "with tf.variable_scope(\"variables_101\"):\n",
    "\tW = tf.Variable([[11,12,13],[13,14,15]], dtype = tf.float32, name='weights')\n",
    "\tb = tf.Variable([[11,12,13]],dtype = tf.float32,name='biases')\n",
    "out_b = tf.Variable([[999,999,999]],dtype = tf.float32,name='variables_101/biases')\n",
    "\n",
    "ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)#提前把EMA存起来\n",
    "ema_op = ema.apply(tf.trainable_variables())\n",
    "\n",
    "\n",
    "for ele2 in tf.all_variables():#比trainable多一个i哦global step：tf.trainable_variables():\n",
    "\tprint(ele2.name)\n",
    "# print('all variables:',get_vars)\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    sess.run(ema_op)#应用一下\n",
    "    save_path = saver.save(sess, \"my_net/save_net_2.ckpt\")\n",
    "    print('Save to path:',save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'variables_101/weights/ExponentialMovingAverage': <tf.Variable 'variables_101/weights:0' shape=(2, 3) dtype=float32_ref>, \n",
    "'variables_101/biases_1/ExponentialMovingAverage': <tf.Variable 'variables_101/biases_1:0' shape=(1, 3) dtype=float32_ref>, \n",
    "'variables_100/weights/ExponentialMovingAverage': <tf.Variable 'variables_100/weights:0' shape=(2, 3) dtype=float32_ref>, \n",
    "'variables_101/biases/ExponentialMovingAverage': <tf.Variable 'variables_101/biases:0' shape=(1, 3) dtype=float32_ref>, \n",
    "'variables_100/biases/ExponentialMovingAverage': <tf.Variable 'variables_100/biases:0' shape=(1, 3) dtype=float32_ref>, \n",
    "'Variable': <tf.Variable 'Variable:0' shape=() dtype=int32_ref>}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'variables_100/biases:0' shape=(1, 3) dtype=float32_ref>\n",
      "<tf.Variable 'variables_101/biases:0' shape=(1, 3) dtype=float32_ref>\n",
      "<tf.Variable 'variables_101/biases_1:0' shape=(1, 3) dtype=float32_ref>\n",
      "INFO:tensorflow:Restoring parameters from my_net/save_net_2.ckpt\n",
      "W2: [[ 1.  2.  3.]\n",
      " [ 3.  4.  5.]]\n",
      "b2: [[ 1.  2.  3.]]\n",
      "W22: [[ 11.  12.  13.]\n",
      " [ 13.  14.  15.]]\n",
      "b22: [[ 11.  12.  13.]]\n",
      "[[ 999.  999.  999.]]\n"
     ]
    }
   ],
   "source": [
    "#with tf.variable_scope(\"variables_1\"):\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "with tf.variable_scope(\"variables_100\"):\n",
    "\tW2 = tf.Variable(np.arange(6).reshape((2,3)), dtype=tf.float32,name='weights')\n",
    "\tb2 = tf.Variable(np.arange(3).reshape((1,3)), dtype=tf.float32,name='biases')\n",
    "with tf.variable_scope(\"variables_101\"):\n",
    "\tW22 = tf.Variable(np.arange(6).reshape((2,3)), dtype=tf.float32,name='weights')\n",
    "\tb22 = tf.Variable(np.arange(3).reshape((1,3)), dtype=tf.float32,name='biases')\n",
    "\n",
    "# out_b = tf.Variable([[66,666,66699]],dtype = tf.float32,name='variables_101/biases')\n",
    "out_b = tf.Variable([[66,666,66699]],dtype = tf.float32,name='variables_101/biases_1')\n",
    "init2 = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "print(b2)\n",
    "print(b22)\n",
    "print(out_b)\n",
    "\n",
    "#no need init\n",
    "loader = tf.train.Saver()\n",
    "load_path = \"my_net/save_net_2.ckpt\"\n",
    "with tf.Session() as sess:\n",
    "#3 way to initialize\n",
    "#\tsess.run(init)#error:not work,sequence problem\n",
    "\t#sess.run(init2)\n",
    "#\tsess.run(init2)\n",
    "    loader.restore(sess, load_path)\n",
    "\n",
    "    print(\"W2:\",sess.run(W2))\n",
    "    print(\"b2:\",sess.run(b2))\n",
    "    print(\"W22:\",sess.run(W22))\n",
    "    print(\"b22:\",sess.run(b22))\n",
    "#\tprint(\"biases2:\",sess.run(b2))\n",
    "    print(sess.run(out_b))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# EMA读取\n",
    "这个ema.variables_to_restore()其实是做映射取代原变量的，下边有例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step:0\n",
      "variables_100/weights:0\n",
      "variables_100/biases:0\n",
      "variables_101/weights:0\n",
      "variables_101/biases:0\n",
      "variables_101/biases_1:0\n",
      "after ema.variables_to_restore()\n",
      "WARNING:tensorflow:From <ipython-input-1-618d71304496>:24: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "global_step:0\n",
      "variables_100/weights:0\n",
      "variables_100/biases:0\n",
      "variables_101/weights:0\n",
      "variables_101/biases:0\n",
      "variables_101/biases_1:0\n",
      "<tf.Variable 'variables_100/biases:0' shape=(1, 3) dtype=float32_ref>\n",
      "<tf.Variable 'variables_101/biases:0' shape=(1, 3) dtype=float32_ref>\n",
      "<tf.Variable 'variables_101/biases_1:0' shape=(1, 3) dtype=float32_ref>\n",
      "ema_restore is  {'variables_100/weights/ExponentialMovingAverage': <tf.Variable 'variables_100/weights:0' shape=(2, 3) dtype=float32_ref>, 'variables_101/biases_1/ExponentialMovingAverage': <tf.Variable 'variables_101/biases_1:0' shape=(1, 3) dtype=float32_ref>, 'variables_100/biases/ExponentialMovingAverage': <tf.Variable 'variables_100/biases:0' shape=(1, 3) dtype=float32_ref>, 'variables_101/biases/ExponentialMovingAverage': <tf.Variable 'variables_101/biases:0' shape=(1, 3) dtype=float32_ref>, 'variables_101/weights/ExponentialMovingAverage': <tf.Variable 'variables_101/weights:0' shape=(2, 3) dtype=float32_ref>, 'global_step': <tf.Variable 'global_step:0' shape=() dtype=int32_ref>}\n",
      "INFO:tensorflow:Restoring parameters from my_net/save_net_2.ckpt\n",
      "W2: [[ 1.  2.  3.]\n",
      " [ 3.  4.  5.]]\n",
      "b2: [[ 1.  2.  3.]]\n",
      "W22: [[ 11.  12.  13.]\n",
      " [ 13.  14.  15.]]\n",
      "b22: [[ 11.  12.  13.]]\n",
      "[[ 999.  999.  999.]]\n",
      "after run restore\n"
     ]
    }
   ],
   "source": [
    "#with tf.variable_scope(\"variables_1\"):\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "MOVING_AVERAGE_DECAY = 0.99\n",
    "global_step = tf.Variable(0, trainable=False,name='global_step')\n",
    "\n",
    "with tf.variable_scope(\"variables_100\"):\n",
    "\tW2 = tf.Variable(np.arange(6).reshape((2,3)), dtype=tf.float32,name='weights')\n",
    "\tb2 = tf.Variable(np.arange(3).reshape((1,3)), dtype=tf.float32,name='biases')\n",
    "with tf.variable_scope(\"variables_101\"):\n",
    "\tW22 = tf.Variable(np.arange(6).reshape((2,3)), dtype=tf.float32,name='weights')\n",
    "\tb22 = tf.Variable(np.arange(3).reshape((1,3)), dtype=tf.float32,name='biases')\n",
    "\n",
    "# out_b = tf.Variable([[66,666,66699]],dtype = tf.float32,name='variables_101/biases')\n",
    "out_b = tf.Variable([[66,666,66699]],dtype = tf.float32,name='variables_101/biases_1')\n",
    "\n",
    "for ele2 in tf.global_variables():#比trainable多一个i哦global step：tf.trainable_variables():\n",
    "\tprint(ele2.name)\n",
    "\n",
    "ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY)\n",
    "ema_restore = ema.variables_to_restore()\n",
    "print('after ema.variables_to_restore()')\n",
    "for ele2 in tf.all_variables():#比trainable多一个,global step                   tf.trainable_variables():\n",
    "\tprint(ele2.name)\n",
    "print(b2)\n",
    "print(b22)\n",
    "print(out_b)\n",
    "\n",
    "print('ema_restore is ',ema_restore)\n",
    "loader = tf.train.Saver(ema_restore)\n",
    "load_path = \"my_net/save_net_2.ckpt\"\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    loader.restore(sess, load_path)\n",
    "\n",
    "    print(\"W2:\",sess.run(W2))\n",
    "    print(\"b2:\",sess.run(b2))\n",
    "    print(\"W22:\",sess.run(W22))\n",
    "    print(\"b22:\",sess.run(b22))\n",
    "    #\tprint(\"biases2:\",sess.run(b2))\n",
    "    print(sess.run(out_b))\n",
    "    \n",
    "    print('after run restore')\n",
    "#     for ele2 in tf.all_variables():#比trainable多一个i哦global step：tf.trainable_variables():\n",
    "#         print(ele2.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "{'variables_100/weights/ExponentialMovingAverage': <tf.Variable 'variables_100/weights:0' shape=(2, 3) dtype=float32_ref>, \n",
    "'variables_101/biases/ExponentialMovingAverage': <tf.Variable 'variables_101/biases:0' shape=(1, 3) dtype=float32_ref>, \n",
    "'variables_101/biases_1/ExponentialMovingAverage': <tf.Variable 'variables_101/biases_1:0' shape=(1, 3) dtype=float32_ref>, \n",
    "'variables_101/weights/ExponentialMovingAverage': <tf.Variable 'variables_101/weights:0' shape=(2, 3) dtype=float32_ref>, \n",
    "'variables_100/biases/ExponentialMovingAverage': <tf.Variable 'variables_100/biases:0' shape=(1, 3) dtype=float32_ref>, 'Variable': <tf.Variable 'Variable:0' shape=() dtype=int32_ref>}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 有EMA的时候，恢复用谁的数值？取决于var_list\n",
    "\n",
    "weights更新是不受ema影响的，训练的时候没什么影响，这是一定的。现在主要说预测的时候，怎么把ema调出来。\n",
    "\n",
    "不指定var_list的时候，原来的'weights'仍然对应'weights'，如果指定了var_list，原来的'weights/ema'会替代'weights'，因为传进去的是个dict，手动的映射，所以说，其实模型改过命名，也不是一定就废弃了，还是可以手动映射来对上的，只不过比较繁琐，我这里就不弄了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init,before assign: [ 10.  20.  30.]\n",
      "global_step is  1\n",
      "W and ema.average: [array([ 10.10000038,  20.10000038,  30.10000038], dtype=float32), array([ 10.,  20.,  30.], dtype=float32)]\n",
      "global_step is  2\n",
      "W and ema.average: [array([ 10.19997215,  20.19997215,  30.19997215], dtype=float32), array([ 10.08181858,  20.08181763,  30.08181763], dtype=float32)]\n",
      "global_step is  3\n",
      "W and ema.average: [array([ 10.29989815,  20.29989815,  30.29989815], dtype=float32), array([ 10.170434  ,  20.17043304,  30.17043304], dtype=float32)]\n",
      "global_step is  4\n",
      "W and ema.average: [array([ 10.39975929,  20.39975929,  30.39975929], dtype=float32), array([ 10.26006317,  20.26006317,  30.26006317], dtype=float32)]\n",
      "global_step is  5\n",
      "W and ema.average: [array([ 10.49953651,  20.49953651,  30.49953651], dtype=float32), array([ 10.34986782,  20.34986877,  30.34986877], dtype=float32)]\n",
      "Save to path: my_net/save_net_3.ckpt\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "MOVING_AVERAGE_DECAY = 0.6#为了观察变化,数值越大，惯性越大，相比实际的W，增长越小越缓慢\n",
    "#0.1的衰减\n",
    "# [array([ 10.49953651,  20.49953651,  30.49953651], dtype=float32), \n",
    "#  array([ 10.38866425,  20.38866425,  30.38866425], dtype=float32)]\n",
    "#0.6的衰减\n",
    "#  [array([ 10.49953651,  20.49953651,  30.49953651], dtype=float32), \n",
    "#   array([ 10.34986782,  20.34986877,  30.34986877], dtype=float32)]\n",
    "\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False,name='global_step')\n",
    "with tf.variable_scope(\"my_scope\"): \n",
    "\tW = tf.Variable([10,20,30], dtype = tf.float32, name='weights')\n",
    "    \n",
    "y = tf.constant([20,30,40],tf.float32)\n",
    "loss = tf.reduce_mean(tf.square(W-y))\n",
    "train_step = tf.train.AdamOptimizer(0.1).minimize(loss,global_step=global_step)\n",
    "    \n",
    "ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)#提前把EMA存起来\n",
    "# ema_op = ema.apply(tf.trainable_variables())\n",
    "ema_op = ema.apply([W])\n",
    "\n",
    "with tf.control_dependencies([train_step, ema_op]):\n",
    "    train_op = tf.no_op(name='train')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print('init,before assign:',sess.run(W))\n",
    "    for i in range(5):\n",
    "        sess.run(train_op)\n",
    "        print('global_step is ',sess.run(global_step))\n",
    "#         sess.run(train_step)\n",
    "#         sess.run(ema_op)\n",
    "        print('W and ema.average:',sess.run([W,ema.average(W)]))\n",
    "\n",
    "    save_path = saver.save(sess, \"my_net/save_net_3.ckpt\")\n",
    "    print('Save to path:',save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step:0\n",
      "my_scope/weights:0\n",
      "ema_restore: {'my_scope/weights/ExponentialMovingAverage': <tf.Variable 'my_scope/weights:0' shape=(3,) dtype=float32_ref>, 'global_step': <tf.Variable 'global_step:0' shape=() dtype=int32_ref>}\n",
      "INFO:tensorflow:Restoring parameters from my_net/save_net_3.ckpt\n",
      "W2: [ 10.49953651  20.49953651  30.49953651]\n",
      "[ 10.49953651  20.49953651  30.49953651]\n",
      "after run restore\n",
      "[<tf.Variable 'global_step:0' shape=() dtype=int32_ref>, <tf.Variable 'my_scope/weights:0' shape=(3,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "#如果不指定var_list，普通的W还是按普通的W去提取。\n",
    "#存[array([ 10.49953651,  20.49953651,  30.49953651], dtype=float32), array([ 10.34986782,  20.34986877,  30.34986877]\n",
    "#取[ 10.49953651  20.49953651  30.49953651]\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "MOVING_AVERAGE_DECAY = 0.6#0.99\n",
    "global_step = tf.Variable(0, trainable=False,name='global_step')\n",
    "\n",
    "with tf.variable_scope(\"my_scope\"):\n",
    "\tW2 = tf.Variable([0,0,0], dtype=tf.float32,name='weights')\n",
    "\n",
    "ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY)\n",
    "ema_restore = ema.variables_to_restore()##w和w的ema，还有global，只能算指定了ema的绑定关系，不是只有ema，其实不影响变量自身的读取\n",
    "\n",
    "# loader = tf.train.Saver(ema_restore)\n",
    "loader = tf.train.Saver()\n",
    "load_path = \"my_net/save_net_3.ckpt\"\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    loader.restore(sess, load_path)\n",
    "\n",
    "    print(\"W2:\",sess.run(W2))\n",
    "#     print(\"W2:\",sess.run([W2,ema.average(W2)]))\n",
    "#     print('ema W is :',sess.run(ema_val))\n",
    "    print(sess.run(ema_restore['my_scope/weights/ExponentialMovingAverage']))\n",
    "    print('after run restore')\n",
    "    print(tf.global_variables())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ema_restore: {'my_scope/weights/ExponentialMovingAverage': <tf.Variable 'my_scope/weights:0' shape=(3,) dtype=float32_ref>, 'my_scope_1/weights/ExponentialMovingAverage': <tf.Variable 'my_scope_1/weights:0' shape=(3,) dtype=float32_ref>, 'global_step_1': <tf.Variable 'global_step_1:0' shape=() dtype=int32_ref>, 'global_step': <tf.Variable 'global_step:0' shape=() dtype=int32_ref>}\n",
      "INFO:tensorflow:Restoring parameters from my_net/save_net_3.ckpt\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Key my_scope_1/weights/ExponentialMovingAverage not found in checkpoint\n\t [[Node: save_1/RestoreV2_3 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_3/tensor_names, save_1/RestoreV2_3/shape_and_slices)]]\n\nCaused by op 'save_1/RestoreV2_3', defined at:\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-957ec92c5b01>\", line 18, in <module>\n    loader = tf.train.Saver(ema_restore)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 751, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 427, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 267, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1021, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key my_scope_1/weights/ExponentialMovingAverage not found in checkpoint\n\t [[Node: save_1/RestoreV2_3 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_3/tensor_names, save_1/RestoreV2_3/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key my_scope_1/weights/ExponentialMovingAverage not found in checkpoint\n\t [[Node: save_1/RestoreV2_3 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_3/tensor_names, save_1/RestoreV2_3/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-957ec92c5b01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W2:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1664\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1666\u001b[0;31m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1667\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key my_scope_1/weights/ExponentialMovingAverage not found in checkpoint\n\t [[Node: save_1/RestoreV2_3 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_3/tensor_names, save_1/RestoreV2_3/shape_and_slices)]]\n\nCaused by op 'save_1/RestoreV2_3', defined at:\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-957ec92c5b01>\", line 18, in <module>\n    loader = tf.train.Saver(ema_restore)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 751, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 427, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 267, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1021, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key my_scope_1/weights/ExponentialMovingAverage not found in checkpoint\n\t [[Node: save_1/RestoreV2_3 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_3/tensor_names, save_1/RestoreV2_3/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "#如果指定var_list，普通的W按ema去提取。\n",
    "#存[array([ 10.49953651,  20.49953651,  30.49953651], dtype=float32), array([ 10.34986782,  20.34986877,  30.34986877]\n",
    "#取[ 10.34986782  20.34986877  30.34986877]\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "MOVING_AVERAGE_DECAY = 0.6#0.99\n",
    "global_step = tf.Variable(0, trainable=False,name='global_step')\n",
    "\n",
    "with tf.variable_scope(\"my_scope\"):\n",
    "\tW2 = tf.Variable([0,0,0], dtype=tf.float32,name='weights')\n",
    "\n",
    "ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY)\n",
    "ema_restore = ema.variables_to_restore()##w和w的ema，还有global，只能算指定了ema的绑定关系，不是只有ema，其实不影响变量自身的读取\n",
    "\n",
    "print('ema_restore:',ema_restore)#这是一个映射，让EMA对应普通变量\n",
    "\n",
    "loader = tf.train.Saver(ema_restore)\n",
    "load_path = \"my_net/save_net_3.ckpt\"\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    loader.restore(sess, load_path)\n",
    "\n",
    "    print(\"W2:\",sess.run(W2))\n",
    "#     print(\"W2:\",sess.run([W2,ema.average(W2)]))\n",
    "#     print('ema W is :',sess.run(ema_val))\n",
    "    print(sess.run(ema_restore['my_scope/weights/ExponentialMovingAverage']))\n",
    "    print('after run restore')\n",
    "    print(tf.global_variables())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 补一发映射的通用写法\n",
    "{'var_name':tensor}\n",
    "通过手动指定，颠倒两个变量的读取和赋值\n",
    "\n",
    "tf.train.Saver的var_list其实支持两种写法，list和dict，dict中的key是文件中的变量名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2: [ 1.  2.  3.]\n",
      "b2: [ 2.  3.  4.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "with tf.variable_scope(\"my_scope\"):\n",
    "\tW2 = tf.Variable([1,2,3], dtype=tf.float32,name='weights')\n",
    "\tb2 = tf.Variable([2,3,4], dtype=tf.float32,name='biases')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "load_path = \"my_net/save_net_4.ckpt\"\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    saver.save(sess, load_path)\n",
    "    print(\"W2:\",sess.run(W2))\n",
    "    print(\"b2:\",sess.run(b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from my_net/save_net_4.ckpt\n",
      "W2: [ 2.  3.  4.]\n",
      "b2: [ 1.  2.  3.]\n",
      "W3: [ 0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "with tf.variable_scope(\"my_scope\"):#颠倒一下\n",
    "\tb2 = tf.Variable([0,0,0], dtype=tf.float32,name='biases')#看name，这里本来也是b2和biases对应的\n",
    "\tW2 = tf.Variable([0,0,0], dtype=tf.float32,name='weightss')#不同名也无所谓\n",
    "\tW3 = tf.Variable([0,0,0], dtype=tf.float32,name='weightsss')\n",
    "\n",
    "#另外，也不能够一个变量恢复到两个tensor，dict中key冲突覆盖了\n",
    "restore_map = {'my_scope/weights':b2,'my_scope/biases':W2#,'my_scope/biases':W3\n",
    "              }\n",
    "loader = tf.train.Saver(restore_map)\n",
    "load_path = \"my_net/save_net_4.ckpt\"\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    loader.restore(sess, load_path)\n",
    "    print(\"W2:\",sess.run(W2))\n",
    "    print(\"b2:\",sess.run(b2))\n",
    "    print(\"W3:\",sess.run(W3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如果定义很多参数，读取model时用不完，冗余，不影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from my_net/save_net_2.ckpt\n",
      "W2: [[ 1.  2.  3.]\n",
      " [ 3.  4.  5.]]\n",
      "b2: [[ 1.  2.  3.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "with tf.variable_scope(\"variables_100\"):\n",
    "\tW2 = tf.Variable(np.arange(6).reshape((2,3)), dtype=tf.float32,name='weights')\n",
    "\tb2 = tf.Variable(np.arange(3).reshape((1,3)), dtype=tf.float32,name='biases')\n",
    "loader = tf.train.Saver()\n",
    "load_path = \"my_net/save_net_2.ckpt\"\n",
    "with tf.Session() as sess:\n",
    "\tloader.restore(sess, load_path)\n",
    "\tprint(\"W2:\",sess.run(W2))\n",
    "\tprint(\"b2:\",sess.run(b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如果原model定义参数少，读取model文件的参数多\n",
    "就算variable有init操作也不允许。就是不行，not found 。因为你没有告诉Saver一个具体的var_list，Saver认为所有变量都需要去文件里找。\n",
    "\n",
    "下边排列组合：怎样调整都不允许，包括把scope 102合并进101,或者改变量名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from my_net/save_net_2.ckpt\n",
      "W2: [[ 0.  1.  2.]\n",
      " [ 3.  4.  5.]]\n",
      "b2: [[ 0.  1.  2.]]\n",
      "W22: [[ 0.  1.  2.]\n",
      " [ 3.  4.  5.]]\n",
      "b22: [[ 0.  1.  2.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "with tf.variable_scope(\"variables_100\"):\n",
    "\tW2 = tf.Variable(np.arange(6).reshape((2,3)), dtype=tf.float32,name='weights')\n",
    "\tb2 = tf.Variable(np.arange(3).reshape((1,3)), dtype=tf.float32,name='biases')\n",
    "with tf.variable_scope(\"variables_101\"):\n",
    "\tW22 = tf.Variable(np.arange(6).reshape((2,3)), dtype=tf.float32,name='weights')\n",
    "\tb22 = tf.Variable(np.arange(3).reshape((1,3)), dtype=tf.float32,name='biases')\n",
    "with tf.variable_scope(\"variables_102\"):\n",
    "\tW23 = tf.Variable(np.arange(6).reshape((2,3)), dtype=tf.float32,name='weights')\n",
    "\tb23 = tf.Variable(np.arange(3).reshape((1,3)), dtype=tf.float32,name='biases')\n",
    "# \tW23 = tf.Variable(np.arange(6).reshape((2,3)), dtype=tf.float32,name='weights23')\n",
    "# \tb23 = tf.Variable(np.arange(3).reshape((1,3)), dtype=tf.float32,name='biases23')\n",
    "\n",
    "init2 = tf.global_variables_initializer()\n",
    "\n",
    "#no need init\n",
    "loader = tf.train.Saver()\n",
    "load_path = \"my_net/save_net_2.ckpt\"\n",
    "with tf.Session() as sess:\n",
    "\tsess.run(init2)\n",
    "\tloader.restore(sess, load_path)\n",
    "\tprint(\"W2:\",sess.run(W2))\n",
    "\tprint(\"b2:\",sess.run(b2))\n",
    "\tprint(\"W22:\",sess.run(W22))\n",
    "\tprint(\"b22:\",sess.run(b22))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如果tf.train.Saver指定var_list只取很少的参数呢？这就行的通了！\n",
    "或者，allow_empty?不是一个东西"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from my_net/save_net_2.ckpt\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Key additional not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-13b2e3255ab0>\", line 22, in <module>\n    loader = tf.train.Saver(allow_empty = True)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 751, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 427, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 267, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1021, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key additional not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key additional not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-13b2e3255ab0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"W2:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1664\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1666\u001b[0;31m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1667\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key additional not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-13b2e3255ab0>\", line 22, in <module>\n    loader = tf.train.Saver(allow_empty = True)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 751, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 427, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 267, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1021, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/qw/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key additional not found in checkpoint\n\t [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "with tf.variable_scope(\"variables_100\"):\n",
    "\tW2 = tf.Variable(np.arange(6).reshape((2,3)), dtype=tf.float32,name='weights')\n",
    "\tb2 = tf.Variable(np.arange(3).reshape((1,3)), dtype=tf.float32,name='biases')\n",
    "with tf.variable_scope(\"variables_101\"):\n",
    "\tW22 = tf.Variable(np.arange(6).reshape((2,3)), dtype=tf.float32,name='weights')\n",
    "\tb22 = tf.Variable(np.arange(3).reshape((1,3)), dtype=tf.float32,name='biases')\n",
    "with tf.variable_scope(\"variables_102\"):\n",
    "\tW23 = tf.Variable(np.arange(6).reshape((2,3)), dtype=tf.float32,name='weights')\n",
    "\tb23 = tf.Variable(np.arange(3).reshape((1,3)), dtype=tf.float32,name='biases')\n",
    "# \tW23 = tf.Variable(np.arange(6).reshape((2,3)), dtype=tf.float32,name='weights23')\n",
    "# \tb23 = tf.Variable(np.arange(3).reshape((1,3)), dtype=tf.float32,name='biases23')\n",
    "\n",
    "additional_variable = tf.Variable(np.arange(6).reshape((2,3)), dtype=tf.float32,name='additional')\n",
    "\n",
    "init2 = tf.global_variables_initializer()\n",
    "\n",
    "#no need init\n",
    "loader = tf.train.Saver([W2,b2,W22,b22])\n",
    "# loader = tf.train.Saver(allow_empty = True)#这个不能解决，不是同一个问题。\n",
    "load_path = \"my_net/save_net_2.ckpt\"\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init2)\n",
    "    loader.restore(sess, load_path)\n",
    "\n",
    "    print(\"W2:\",sess.run(W2))\n",
    "    print(\"b2:\",sess.run(b2))\n",
    "    print(\"W22:\",sess.run(W22))\n",
    "    print(\"b22:\",sess.run(b22))\n",
    "    print('W23:',sess.run(W23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#same shape and same type and same name?\n",
    "#W2 = tf.Variable(np.arange(6).reshape((2,3)), dtype=tf.float32,name='weights2')#wrong name\n",
    "#b2 = tf.Variable(np.arange(3).reshape((1,3)), dtype=tf.float32,name='biases2')\n",
    "#W2 = tf.Variable(np.arange(6).reshape((2,3)), dtype=tf.float32,name='weights')\n",
    "#b2 = tf.Variable(np.arange(3).reshape((1,3)), dtype=tf.float32,name='biases')\n",
    "#b3 = tf.Variable(np.arange(3).reshape((1,3)), dtype=tf.float32,name='biases3')#wrong name too!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #allow_empty是创建空graph用的，todo\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# # with tf.variable_scope(\"variables_100\"):\n",
    "# # \tW2 = tf.Variable(np.arange(6).reshape((2,3)), dtype=tf.float32,name='weights')\n",
    "\n",
    "# saver = tf.train.Saver()\n",
    "# save_path = \"my_net/save_net_233.ckpt\"\n",
    "# with tf.Session() as sess:\n",
    "# \ttf.global_variables_initializer().run()\n",
    "# \tsaver.save(sess, save_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method restore in module tensorflow.python.training.saver:\n",
      "\n",
      "restore(sess, save_path) method of tensorflow.python.training.saver.Saver instance\n",
      "    Restores previously saved variables.\n",
      "    \n",
      "    This method runs the ops added by the constructor for restoring variables.\n",
      "    It requires a session in which the graph was launched.  The variables to\n",
      "    restore do not have to have been initialized, as restoring is itself a way\n",
      "    to initialize variables.\n",
      "    \n",
      "    The `save_path` argument is typically a value previously returned from a\n",
      "    `save()` call, or a call to `latest_checkpoint()`.\n",
      "    \n",
      "    Args:\n",
      "      sess: A `Session` to use to restore the parameters.\n",
      "      save_path: Path where parameters were previously saved.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(loader.restore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "这烦人的重名问题怎么解决？get_variable？！！！！但是scope一样会自动重命名，不能解决，只能解决没scope的情况\n",
    "tf.get_variable_scope就是另一种用途了。\n",
    "help(tf.get_variable)#注意，第一个默认就是name，小心重名。关于data，应该用initializer吧。\n",
    "help(tf.get_variable_scope)\n",
    "# import tensorflow as tf\n",
    "# with tf.variable_scope(\"variables_100\"): \n",
    "# \tW = tf.get_variable(name='weights', dtype = tf.float32)\n",
    "# \tb = tf.get_variable(name='biases',dtype = tf.float32)\n",
    "\n",
    "# init = tf.global_variables_initializer()\n",
    "# variable_set = tf.get_variable_scope()\n",
    "# print(W)\n",
    "# print(variable_set)\n",
    "# saver = tf.train.Saver()\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "#     save_path = saver.save(sess, \"my_net/save_net_2.ckpt\")\n",
    "#     print('Save to path:',save_path)\n",
    "#     print(sess.run(variable_set))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
