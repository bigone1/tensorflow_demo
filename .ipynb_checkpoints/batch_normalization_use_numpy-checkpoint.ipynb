{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO：还没看完。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前向传播\n",
    "这个典型公式和下边代码能对应上decay换成momentum：\n",
    "moving_mean = moving_mean * decay + new_batch_mean * (1 - decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#抄写，拆解\n",
    "#参数：输入，gamma、beta，bn_param是一个参数dict{mode:,eps:,momentum:,running_mean:,running_var:}\n",
    "#运行时平均值和方差是从参数带进来的。\n",
    "#返回是out和cache，cache是反向传播用的。\n",
    "def batchnorm_forward(x, gamma, beta, bn_param):\n",
    "    mode = bn_param['mode']\n",
    "\n",
    "    \n",
    "x = np.array([1,2,3])\n",
    "batchnorm_forward(x,gamma = [1,1,1], beta = [0,0,0], bn_param={'mode':'train'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batchnorm_forward(x, gamma, beta, bn_param):\n",
    "    mode = bn_param['mode']\n",
    "\n",
    "    mode = bn_param['mode']\n",
    "    eps = bn_param.get('eps', 1e-5)\n",
    "    momentum = bn_param.get('momentum', 0.9)\n",
    "\n",
    "    N, D = x.shape\n",
    "    running_mean = bn_param.get('running_mean', np.zeros(D, dtype=x.dtype))\n",
    "    running_var = bn_param.get('running_var', np.zeros(D, dtype=x.dtype))\n",
    "\n",
    "    out, cache = None, None\n",
    "    \n",
    "    if mode == 'train':\n",
    "\n",
    "        sample_mean = np.mean(x, axis=0)\n",
    "        sample_var = np.var(x, axis=0)\n",
    "        out_ = (x - sample_mean) / np.sqrt(sample_var + eps)\n",
    "\n",
    "        running_mean = momentum * running_mean + (1 - momentum) * sample_mean\n",
    "        running_var = momentum * running_var + (1 - momentum) * sample_var\n",
    "\n",
    "        out = gamma * out_ + beta\n",
    "        cache = (out_, x, sample_var, sample_mean, eps, gamma, beta)\n",
    "\n",
    "    elif mode == 'test':\n",
    "\n",
    "        scale = gamma / np.sqrt(running_var + eps)\n",
    "        out = x * scale + (beta - running_mean * scale)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Invalid forward batchnorm mode \"%s\"' % mode)\n",
    "\n",
    "    # Store the updated running means back into bn_param\n",
    "    bn_param['running_mean'] = running_mean\n",
    "    bn_param['running_var'] = running_var\n",
    "\n",
    "    return out, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#原实现\n",
    "def batchnorm_forward(x, gamma, beta, bn_param):\n",
    "    \"\"\"\n",
    "    Forward pass for batch normalization.\n",
    "\n",
    "    Input:\n",
    "    - x: Data of shape (N, D)\n",
    "    - gamma: Scale parameter of shape (D,)\n",
    "    - beta: Shift paremeter of shape (D,)\n",
    "    - bn_param: Dictionary with the following keys:\n",
    "    - mode: 'train' or 'test'; required\n",
    "    - eps: Constant for numeric stability\n",
    "    - momentum: Constant for running mean / variance.\n",
    "    - running_mean: Array of shape (D,) giving running mean of features\n",
    "    - running_var Array of shape (D,) giving running variance of features\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - out: of shape (N, D)\n",
    "    - cache: A tuple of values needed in the backward pass\n",
    "    \"\"\"\n",
    "    mode = bn_param['mode']\n",
    "    eps = bn_param.get('eps', 1e-5)\n",
    "    momentum = bn_param.get('momentum', 0.9)\n",
    "\n",
    "    N, D = x.shape\n",
    "    running_mean = bn_param.get('running_mean', np.zeros(D, dtype=x.dtype))\n",
    "    running_var = bn_param.get('running_var', np.zeros(D, dtype=x.dtype))\n",
    "\n",
    "    out, cache = None, None\n",
    "    \n",
    "    if mode == 'train':\n",
    "\n",
    "        sample_mean = np.mean(x, axis=0)\n",
    "        sample_var = np.var(x, axis=0)\n",
    "        out_ = (x - sample_mean) / np.sqrt(sample_var + eps)\n",
    "\n",
    "        running_mean = momentum * running_mean + (1 - momentum) * sample_mean\n",
    "        running_var = momentum * running_var + (1 - momentum) * sample_var\n",
    "\n",
    "        out = gamma * out_ + beta\n",
    "        cache = (out_, x, sample_var, sample_mean, eps, gamma, beta)\n",
    "\n",
    "    elif mode == 'test':\n",
    "\n",
    "        scale = gamma / np.sqrt(running_var + eps)\n",
    "        out = x * scale + (beta - running_mean * scale)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Invalid forward batchnorm mode \"%s\"' % mode)\n",
    "\n",
    "    # Store the updated running means back into bn_param\n",
    "    bn_param['running_mean'] = running_mean\n",
    "    bn_param['running_var'] = running_var\n",
    "\n",
    "    return out, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 反向传播\n",
    "公式暂时不推了https://zhuanlan.zhihu.com/p/26138673"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#原实现\n",
    "def batchnorm_backward(dout, cache):\n",
    "    \"\"\"\n",
    "    Backward pass for batch normalization.\n",
    "\n",
    "    Inputs:\n",
    "    - dout: Upstream derivatives, of shape (N, D)\n",
    "    - cache: Variable of intermediates from batchnorm_forward.\n",
    "\n",
    "    Returns a tuple of:\n",
    "    - dx: Gradient with respect to inputs x, of shape (N, D)\n",
    "    - dgamma: Gradient with respect to scale parameter gamma, of shape (D,)\n",
    "    - dbeta: Gradient with respect to shift parameter beta, of shape (D,)\n",
    "    \"\"\"\n",
    "    dx, dgamma, dbeta = None, None, None\n",
    "\n",
    "    out_, x, sample_var, sample_mean, eps, gamma, beta = cache\n",
    "\n",
    "    N = x.shape[0]\n",
    "    dout_ = gamma * dout\n",
    "    dvar = np.sum(dout_ * (x - sample_mean) * -0.5 * (sample_var + eps) ** -1.5, axis=0)\n",
    "    dx_ = 1 / np.sqrt(sample_var + eps)\n",
    "    dvar_ = 2 * (x - sample_mean) / N\n",
    "\n",
    "    # intermediate for convenient calculation\n",
    "    di = dout_ * dx_ + dvar * dvar_\n",
    "    dmean = -1 * np.sum(di, axis=0)\n",
    "    dmean_ = np.ones_like(x) / N\n",
    "\n",
    "    dx = di + dmean * dmean_\n",
    "    dgamma = np.sum(dout * out_, axis=0)\n",
    "    dbeta = np.sum(dout, axis=0)\n",
    "\n",
    "    return dx, dgamma, dbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
